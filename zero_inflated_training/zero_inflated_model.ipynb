{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f9213e",
   "metadata": {},
   "source": [
    "\n",
    "Findings: \n",
    "\n",
    "The higher I make this the more accurate the classifier gets in terms of predicting non binding\n",
    "\n",
    "Thus with more samples in zero binding we get less samples in training on binding which makes the mse much worse (the model simply cannot find a way to predicting strong binding values)\n",
    "\n",
    "no matter what combinations I try, wether it be the non binding threshold, the zero_pred_threshold, or the layers in a binding predictor. I cannot even mean the mse of our mean predictor.\n",
    "\n",
    "leaves me with the conclusion that there are not enough samples with a strong binding value in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bea013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, GATConv, global_add_pool, global_max_pool\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "from rdkit.Chem.rdchem import ChiralType\n",
    "from rdkit.Chem.rdchem import BondType\n",
    "from rdkit.Chem.rdchem import BondStereo\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import rdkit.Chem as Chem\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from typing import Tuple, List, Dict, Optional, Union\n",
    "\n",
    "from lightning.pytorch.utilities.combined_loader import CombinedLoader\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc753a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_glycans(glycans, radius, fp_size, n_clusters):\n",
    "\n",
    "    def get_morgan_count_fingerprint(smiles, radius, fp_size):\n",
    "        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return {f\"mf_{i}\": 0 for i in range(fp_size)} \n",
    "\n",
    "\n",
    "        #The useChirality parameter in Morgan fingerprints determines whether chirality is considered when encoding a molecule.\n",
    "        #includeChirality=True = Differentiates between enantiomers (model will treat mirror-image molecules as different)\n",
    "        #includeChirality=False = Ignores chirality (model will treat mirror-image molecules as the same)\n",
    "        kid_named_morgan_finger = rdFingerprintGenerator.GetMorganGenerator(radius=radius,fpSize=fp_size, includeChirality=True)\n",
    "\n",
    "        cfp = kid_named_morgan_finger.GetCountFingerprint(mol)  \n",
    "        bit_counts = cfp.GetNonzeroElements()  \n",
    "\n",
    "        # Convert to a full fp_size-length feature vector\n",
    "        fingerprint_vector = {f\"mf_{i}\": bit_counts.get(i, 0) for i in range(fp_size)}\n",
    "        return fingerprint_vector\n",
    "\n",
    "    fingerprint_df = glycans['SMILES'].apply(lambda x: get_morgan_count_fingerprint(x, radius, fp_size)).apply(pd.Series)\n",
    "    \n",
    "    glycans = pd.concat([glycans, fingerprint_df], axis=1)\n",
    "    \n",
    "    # matrix version of fingerprint features. Each row is a glycan, each column is a fingerprint component shape: (611, 2048)\n",
    "    finger_counts_matrix = fingerprint_df.values\n",
    "    # pdist calculates the euclidean distance between the combination of each glycan with every other glycan. Then squareform() turns this into a matrix representation where each row is a glycan and each column is the same list of glycans so we can have a comparison matrix. Shape: (611, 611)\n",
    "    dist_matrix = squareform(pdist(finger_counts_matrix, metric=\"euclidean\"))\n",
    "    \n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    labels = kmeans.fit_predict(dist_matrix)\n",
    "    \n",
    "    glycans['cluster_label'] = labels\n",
    "    \n",
    "    return glycans\n",
    "\n",
    "def cluster_proteins(proteins, n_clusters):\n",
    "    \n",
    "    \n",
    "    def compute_protein_features(seq):\n",
    "\n",
    "        # Add reasoning for feature vectors\n",
    "        \n",
    "        # Protein Analysis is a Tool from Biopython\n",
    "        analysis = ProteinAnalysis(seq)\n",
    "        features = {}\n",
    "        \n",
    "        # The following are Basic Features\n",
    "        features['length'] = len(seq)\n",
    "        features['mw'] = analysis.molecular_weight()\n",
    "        features['instability_index'] = analysis.instability_index()\n",
    "\n",
    "        features['net_charge_pH7'] = analysis.charge_at_pH(7.0)\n",
    "\n",
    "        aa_percent = analysis.get_amino_acids_percent()\n",
    "\n",
    "        # Prompted ChatGPT to ask how to parse a\n",
    "        # N, Q, S, T: Polar Amino Acids, often involved in hydrogen bonding with glycans\n",
    "        # K, R: Basic Amino Acids, can form hydrogen bonds and electrostatic bonds\n",
    "        # D, E: Acidic Amino Acids, can interact with positively charged groups of glycans\n",
    "        for aa in ['N', 'Q', 'S', 'T', 'K', 'R', 'D', 'E']:\n",
    "            features[f'frac_{aa}'] = aa_percent.get(aa, 0.0)\n",
    "\n",
    "    \n",
    "    # F, Y, W are aromatic amino acids which bind with glycans\n",
    "        for aa in ['F', 'Y', 'W']:\n",
    "            features[f'frac_{aa}'] = aa_percent.get(aa, 0.0)\n",
    "            features['aromatic_binding_score'] = (\n",
    "            aa_percent.get('F', 0.0) +\n",
    "            aa_percent.get('Y', 0.0) +\n",
    "            aa_percent.get('W', 0.0)\n",
    "        )\n",
    "\n",
    "        features['aromaticity'] = analysis.aromaticity()\n",
    "\n",
    "        features['hydrophobicity'] = analysis.gravy()\n",
    "\n",
    "        return features\n",
    "\n",
    "    feature_dicts = proteins['Amino Acid Sequence'].apply(compute_protein_features)\n",
    "    features_df = pd.DataFrame(list(feature_dicts))\n",
    "\n",
    "    proteins = pd.concat([proteins, features_df], axis=1)\n",
    "    \n",
    "    # Select the feature columns (all columns from the feature extraction)\n",
    "    feature_columns = features_df.columns.tolist()\n",
    "    feature_data = proteins[feature_columns].values\n",
    "\n",
    "    # apply k means clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    proteins['cluster_label'] = kmeans.fit_predict(feature_data)\n",
    "    \n",
    "    return proteins\n",
    "\n",
    "def stratified_train_test_split(fractions_df, glycans_df, proteins_df, test_size, random_state, mode='AND'):\n",
    "    \"\"\"\n",
    "    Create a stratified train-test split where:\n",
    "    1. Test set has unique GlycanIDs and ProteinGroups not seen in training\n",
    "    2. Distribution of cluster_labels for both glycans and proteins is maintained\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fractions_df : pandas.DataFrame\n",
    "        DataFrame containing ['ObjId', 'ProteinGroup', 'Concentration', 'GlycanID', 'f']\n",
    "    glycans_df : pandas.DataFrame\n",
    "        DataFrame containing ['Name', 'cluster_label'] where Name maps to GlycanID\n",
    "    proteins_df : pandas.DataFrame\n",
    "        DataFrame containing ['ProteinGroup', 'cluster_label']\n",
    "    test_size : float, default=0.1\n",
    "        Proportion of data to include in the test set\n",
    "    random_state : int, default=42\n",
    "        Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    train_indices : numpy.ndarray\n",
    "        Indices of fractions_df that belong to the training set\n",
    "    test_indices : numpy.ndarray\n",
    "        Indices of fractions_df that belong to the test set\n",
    "    \"\"\"\n",
    "    # Set random seed\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Merge cluster labels from glycans and proteins into fractions\n",
    "    fractions_with_clusters = fractions_df.copy()\n",
    "    \n",
    "    # Map glycan cluster labels\n",
    "    glycan_cluster_map = dict(zip(glycans_df['Name'], glycans_df['cluster_label']))\n",
    "    fractions_with_clusters['glycan_cluster'] = fractions_with_clusters['GlycanID'].map(glycan_cluster_map)\n",
    "    \n",
    "    # Map protein cluster labels\n",
    "    protein_cluster_map = dict(zip(proteins_df['ProteinGroup'], proteins_df['cluster_label']))\n",
    "    fractions_with_clusters['protein_cluster'] = fractions_with_clusters['ProteinGroup'].map(protein_cluster_map)\n",
    "    \n",
    "    # Get unique glycans and proteins with their cluster labels\n",
    "    unique_glycans = glycans_df[['Name', 'cluster_label']].drop_duplicates()\n",
    "    unique_proteins = proteins_df[['ProteinGroup', 'cluster_label']].drop_duplicates()\n",
    "    \n",
    "    # Calculate target counts for each cluster in test set\n",
    "    glycan_cluster_counts = unique_glycans['cluster_label'].value_counts().to_dict()\n",
    "    protein_cluster_counts = unique_proteins['cluster_label'].value_counts().to_dict()\n",
    "    \n",
    "    glycan_test_counts = {cluster: max(1, int(np.ceil(count * test_size))) \n",
    "                         for cluster, count in glycan_cluster_counts.items()}\n",
    "    protein_test_counts = {cluster: max(1, int(np.ceil(count * test_size))) \n",
    "                          for cluster, count in protein_cluster_counts.items()}\n",
    "    \n",
    "    # Select glycans and proteins for test set while respecting cluster distributions\n",
    "    test_glycans = []\n",
    "    for cluster, target_count in glycan_test_counts.items():\n",
    "        cluster_glycans = unique_glycans[unique_glycans['cluster_label'] == cluster]['Name'].tolist()\n",
    "        selected = np.random.choice(cluster_glycans, size=min(target_count, len(cluster_glycans)), replace=False)\n",
    "        test_glycans.extend(selected)\n",
    "    \n",
    "    test_proteins = []\n",
    "    for cluster, target_count in protein_test_counts.items():\n",
    "        cluster_proteins = unique_proteins[unique_proteins['cluster_label'] == cluster]['ProteinGroup'].tolist()\n",
    "        selected = np.random.choice(cluster_proteins, size=min(target_count, len(cluster_proteins)), replace=False)\n",
    "        test_proteins.extend(selected)\n",
    "        \n",
    "        \n",
    "    if mode == 'AND':\n",
    "        \n",
    "        is_test = ((fractions_df['GlycanID'].isin(test_glycans)) & \n",
    "                (fractions_df['ProteinGroup'].isin(test_proteins)))\n",
    "\n",
    "        is_train = ((~fractions_df['GlycanID'].isin(test_glycans)) & \n",
    "                        (~fractions_df['ProteinGroup'].isin(test_proteins)))\n",
    "                \n",
    "        test_indices = fractions_df[is_test].index\n",
    "\n",
    "        train_indices = fractions_df[is_train].index\n",
    "        \n",
    "        print(f'-------------Test size (% of glycans and proteins as combinations in test set): {test_size*100}% -------------')\n",
    "\n",
    "        print(f'train size: {len(train_indices)}, test size: {len(test_indices)}, total: {len(fractions_df)}')\n",
    "                \n",
    "        print(f'train size: {round((len(train_indices)/len(fractions_df))*100, 2)}%, test size: {round((len(test_indices)/len(fractions_df))*100, 2)}%')\n",
    "        \n",
    "        print(f'test size % in terms of test/(training+test) size: {round((len(test_indices)/(len(train_indices)+len(test_indices)))*100, 2)}%')\n",
    "        \n",
    "        print(f'Total % of dataset used: {round(((len(train_indices)+len(test_indices))/len(fractions_df))*100, 2)}%\\n')\n",
    "    \n",
    "    else:\n",
    "        print('OR operation selected')\n",
    "        # Create train and test masks\n",
    "        is_test = ((fractions_with_clusters['GlycanID'].isin(test_glycans)) | \n",
    "                (fractions_with_clusters['ProteinGroup'].isin(test_proteins)))\n",
    "        \n",
    "        test_indices = fractions_with_clusters[is_test].index\n",
    "        train_indices = fractions_with_clusters[~is_test].index\n",
    "    \n",
    "    \n",
    "    return train_indices, test_indices\n",
    "\n",
    "def batch_encode(encoder, data_list, device, batch_size):\n",
    "    \"\"\"Process data in batches to avoid CUDA memory overflow\"\"\"\n",
    "    all_encodings = []\n",
    "    total_items = len(data_list)\n",
    "    \n",
    "    for i in range(0, total_items, batch_size):\n",
    "        # Get current batch\n",
    "        batch = data_list[i:min(i+batch_size, total_items)]\n",
    "        \n",
    "        # Encode batch\n",
    "        batch_encodings = encoder.encode_batch(batch, device)\n",
    "        all_encodings.append(batch_encodings)\n",
    "        \n",
    "        # Print progress\n",
    "        print(f'Progress: {min(i+batch_size, total_items)}/{total_items}')\n",
    "        \n",
    "        # Optional: clear CUDA cache to prevent memory fragmentation\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    return torch.cat(all_encodings, dim=0)\n",
    "\n",
    "def prepare_train_val_datasets(\n",
    "    fractions_df: pd.DataFrame,\n",
    "    glycans_df: pd.DataFrame,\n",
    "    proteins_df: pd.DataFrame,\n",
    "    glycan_encoder,\n",
    "    protein_encoder,\n",
    "    glycan_type: str,\n",
    "    random_state: int,\n",
    "    split_mode: str,\n",
    "    use_kfolds: bool,\n",
    "    k_folds: float,\n",
    "    val_split: float,\n",
    "    device: torch.device\n",
    ") -> Tuple[Dataset, Dataset]:\n",
    "    \"\"\"\n",
    "    Prepare train and validation datasets\n",
    "    \n",
    "    Args:\n",
    "        df: Full dataset DataFrame\n",
    "        val_split: Fraction of data to use for validation\n",
    "        glycan_encoder: Encoder for glycans\n",
    "        protein_encoder: Encoder for proteins\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of train and validation datasets\n",
    "    \"\"\"\n",
    "    \n",
    "    # for each glycan create a glycan_encoding feature where we use glycan_encoder to encode the SMILES\n",
    "    # for each protein create a protein_encoding feature where we use protein_encoder to encode the aminoacids\n",
    "    #glycan_encodings = glycan_encoder.encode_batch(glycans_df[glycan_type].tolist(), device)\n",
    "    #protein_encodings = protein_encoder.encode_batch(proteins_df['Amino Acid Sequence'].tolist(), device)\n",
    "\n",
    "    # only do batch to not overload RAM of GPU\n",
    "    if device.type == 'cuda':\n",
    "        batch_size = 100  # Adjust based on your GPU memory\n",
    "\n",
    "        # Encode glycans in batches\n",
    "        glycan_encodings = batch_encode(\n",
    "            glycan_encoder, \n",
    "            glycans_df[glycan_type].tolist(), \n",
    "            device, \n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "        # Encode proteins in batches\n",
    "        protein_encodings = batch_encode(\n",
    "            protein_encoder, \n",
    "            proteins_df['Amino Acid Sequence'].tolist(), \n",
    "            device, \n",
    "            batch_size=batch_size\n",
    "        )\n",
    "    else:\n",
    "        glycan_encodings = glycan_encoder.encode_batch(glycans_df[glycan_type].tolist(), device)\n",
    "        protein_encodings = protein_encoder.encode_batch(proteins_df['Amino Acid Sequence'].tolist(), device)\n",
    "    \n",
    "    \n",
    "    # Might move to config but leave for now as our train and test are clusterd and stratified using these parameters\n",
    "    radius = 3\n",
    "    fp_size = 1024\n",
    "    n_clusters = 3\n",
    "    glycans_df = cluster_glycans(glycans_df, radius, fp_size, n_clusters)\n",
    "    \n",
    "    n_protein_clusters = 3\n",
    "    proteins_df = cluster_proteins(proteins_df, n_protein_clusters)\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_indicies, test_indicies = stratified_train_test_split(fractions_df, glycans_df, proteins_df, val_split, random_state, split_mode)\n",
    "    # convert to kfold format so we can use the same code\n",
    "    full_indicies = [(train_indicies, test_indicies)]\n",
    "    \n",
    "    return full_indicies, glycan_encodings, protein_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecd24a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNNGlycanEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim: int = 128, pos_emb_dim: int = 2,\n",
    "                 hidden_state_size: int = 128, n_layers: int = 3):\n",
    "        super().__init__()\n",
    "\n",
    "        # Node features (118 + 1 + 1 + 1 + 4 = 125 dimensions)\n",
    "        self.node_features = [\n",
    "            'atomic_num',\n",
    "            'mass',\n",
    "            'row',\n",
    "            'column',\n",
    "            #'chirality',\n",
    "        ]\n",
    "        \n",
    "        # Edge features (4 + 4 + 1 + 1 + 1 = 11 dimensions)\n",
    "        self.edge_features = [\n",
    "            'bond_type',\n",
    "            'stero_configuration',\n",
    "            #'is_in_ring',\n",
    "            #'is_conjugated',\n",
    "            #'is_aromatic',\n",
    "        ]\n",
    "        \n",
    "        self._embedding_dim = embedding_dim\n",
    "        self.pos_emb_dim = pos_emb_dim\n",
    "        self.hidden_state_size = hidden_state_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Assume base node features have 125 dimensions.\n",
    "        # (For example: one-hot atomic number (118) + mass (1) + row (1) + column (1) + chirality one-hot (4))\n",
    "        self.base_node_feature_dim = 118 + 1 + 1 + 1 # + 4\n",
    "        \n",
    "        # After concatenating positional and structural embeddings, node feature dim becomes:\n",
    "        self.node_feature_dim = self.base_node_feature_dim + self.pos_emb_dim + 2\n",
    "\n",
    "        # Edge features dimension (example): 11.\n",
    "        # (For example: bond type one-hot (4) + stereo configuration one-hot (4) + is_in_ring (1) + is_conjugated (1) + is_aromatic (1))\n",
    "        self.edge_feature_dim = 4 + 4 # + 1 + 1 + 1\n",
    "\n",
    "         # Initial projection to hidden state.\n",
    "        self.initial_linear = nn.Linear(self.node_feature_dim, self.hidden_state_size)\n",
    "\n",
    "        # Message passing function\n",
    "        self.f_message = nn.Sequential(\n",
    "            nn.Linear(self.hidden_state_size + self.edge_feature_dim, self.hidden_state_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(self.hidden_state_size, self.hidden_state_size)\n",
    "        )\n",
    "        \n",
    "        # Update function\n",
    "        self.f_update = nn.Sequential(\n",
    "            nn.Linear(2 * self.hidden_state_size, self.hidden_state_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(self.hidden_state_size, self.hidden_state_size)\n",
    "        )\n",
    "\n",
    "        # Final readout projection.\n",
    "        self.f_readout = nn.Linear(self.hidden_state_size, self._embedding_dim)\n",
    "        \n",
    "    def _get_random_walk_stats(self, adj: torch.Tensor, k_steps: int = 8) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute a k-step random walk bias matrix R = T^k (with T = D^-1 * A),\n",
    "        and then derive per-node statistics (mean and std) for each node.\n",
    "        Returns a tensor of shape (N, 2) where the two columns are mean and std.\n",
    "        \"\"\"\n",
    "        deg = torch.sum(adj, dim=1, keepdim=True) + 1e-6\n",
    "        T = adj / deg\n",
    "        R = T.clone()\n",
    "        for _ in range(k_steps - 1):\n",
    "            R = R @ T\n",
    "        # For each node, compute mean and standard deviation across the row.\n",
    "        r_mean = R.mean(dim=1, keepdim=True)  # (N, 1)\n",
    "        r_std = R.std(dim=1, keepdim=True)    # (N, 1)\n",
    "        return torch.cat([r_mean, r_std], dim=1)  # (N, 2)\n",
    "\n",
    "\n",
    "    def _get_positional_embeddings(self, adj: torch.Tensor, k: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute k-dimensional positional embeddings using the Laplacian eigenvectors.\n",
    "        adj: (N, N) adjacency matrix.\n",
    "        Returns: Tensor of shape (N, k)\n",
    "        \"\"\"\n",
    "        # Compute degree vector and construct degree matrix D.\n",
    "        deg = torch.sum(adj, dim=1)\n",
    "        D = torch.diag(deg)\n",
    "        # Compute Laplacian: L = D - A.\n",
    "        L = D - adj\n",
    "        # Compute eigen-decomposition (eigenvalues in ascending order).\n",
    "        eigenvalues, eigenvectors = torch.linalg.eigh(L)\n",
    "        # Skip the first eigenvector (trivial constant vector) if possible.\n",
    "        if k < L.size(0):\n",
    "            pos_emb = eigenvectors[:, 1:k+1]\n",
    "        else:\n",
    "            pos_emb = eigenvectors[:, :k]\n",
    "        return pos_emb\n",
    "    \n",
    "    def _one_hot_atomic_number(self, atom):\n",
    "        one_hot = [0] * 118\n",
    "        atomic_num = atom.GetAtomicNum()\n",
    "        one_hot[atomic_num - 1] = 1\n",
    "        return one_hot\n",
    "    \n",
    "    def _one_hot_chirality(self, atom):\n",
    "        chiral_tag = atom.GetChiralTag()\n",
    "        possible_tags = [\n",
    "            ChiralType.CHI_UNSPECIFIED, \n",
    "            ChiralType.CHI_TETRAHEDRAL_CW, \n",
    "            ChiralType.CHI_TETRAHEDRAL_CCW, \n",
    "            ChiralType.CHI_OTHER,\n",
    "        ]\n",
    "        one_hot = [1 if chiral_tag == tag else 0 for tag in possible_tags]\n",
    "        return one_hot\n",
    "\n",
    "    def _one_hot_bond_type(self, bond):\n",
    "        bond_type = bond.GetBondType()\n",
    "        possible_types = [\n",
    "            BondType.SINGLE,\n",
    "            BondType.DOUBLE,\n",
    "            BondType.TRIPLE,\n",
    "            BondType.AROMATIC,\n",
    "        ]\n",
    "        one_hot = [1 if bond_type == type else 0 for type in possible_types]\n",
    "        return one_hot\n",
    "    \n",
    "    def _one_hot_stereo_configuration(self, bond):\n",
    "        stereo = bond.GetStereo()\n",
    "        possible_configurations = [\n",
    "            BondStereo.STEREOANY,\n",
    "            BondStereo.STEREOZ,\n",
    "            BondStereo.STEREOE,\n",
    "            BondStereo.STEREONONE,\n",
    "        ]\n",
    "        one_hot = [1 if stereo == config else 0 for config in possible_configurations]\n",
    "        return one_hot\n",
    "    \n",
    "    def _get_atom_features(self, atom) -> List[float]:\n",
    "        \"\"\"Extract atom features according to the predefined list\"\"\"\n",
    "        features = []\n",
    "\n",
    "        # atomic number one hot encoding\n",
    "        features += self._one_hot_atomic_number(atom)\n",
    "\n",
    "        # atomic mass\n",
    "        features.append(atom.GetMass())\n",
    "\n",
    "        # row in periodic table / period\n",
    "        features.append(element_row[atom.GetSymbol()])\n",
    "\n",
    "        # column in periodic table / group\n",
    "        features.append(element_col[atom.GetSymbol()])\n",
    "\n",
    "        # chirality one hot encoding\n",
    "        #features += self._one_hot_chirality(atom)\n",
    "\n",
    "        return features\n",
    "    \n",
    "    def _get_bond_features(self, bond) -> List[float]:\n",
    "        \"\"\"Extract bond features according to the predefined list\"\"\"\n",
    "        features = []\n",
    "\n",
    "        # bond type one hot encoding\n",
    "        features += self._one_hot_bond_type(bond)\n",
    "\n",
    "        # stereo configuration one hot encoding\n",
    "        features += self._one_hot_stereo_configuration(bond)\n",
    "\n",
    "        # is in ring\n",
    "        #features.append(bond.IsInRing())\n",
    "\n",
    "        # is conjugated\n",
    "        #features.append(bond.GetIsConjugated())\n",
    "\n",
    "        # is aromatic\n",
    "        #features.append(bond.GetIsAromatic())\n",
    "\n",
    "        return features\n",
    "    \n",
    "    def _mol_to_graph_data(self, mol) -> dict:\n",
    "        \"\"\"\n",
    "        Convert an RDKit molecule to a graph data dictionary containing:\n",
    "          - x: node feature matrix (N x node_feature_dim)\n",
    "          - adj: adjacency matrix (N x N)\n",
    "          - edge_attr: edge feature tensor (N x N x edge_feature_dim)\n",
    "          - batch: tensor indicating graph membership (for a single graph, all zeros)\n",
    "        \"\"\"\n",
    "        # Build node features.\n",
    "        node_features = [self._get_atom_features(atom) for atom in mol.GetAtoms()]\n",
    "        x_raw = torch.tensor(node_features, dtype=torch.float)  # Shape: (N, node_feature_dim)\n",
    "        N = x_raw.size(0)\n",
    "        \n",
    "        # Initialize dense adjacency and edge feature matrices.\n",
    "        adj = torch.zeros((N, N), dtype=torch.float)\n",
    "        edge_attr = torch.zeros((N, N, self.edge_feature_dim), dtype=torch.float)\n",
    "        \n",
    "        # Populate matrices for each bond.\n",
    "        for bond in mol.GetBonds():\n",
    "            i = bond.GetBeginAtomIdx()\n",
    "            j = bond.GetEndAtomIdx()\n",
    "            adj[i, j] = 1.0\n",
    "            adj[j, i] = 1.0\n",
    "            bf = self._get_bond_features(bond)\n",
    "            bf_tensor = torch.tensor(bf, dtype=torch.float)\n",
    "            edge_attr[i, j] = bf_tensor\n",
    "            edge_attr[j, i] = bf_tensor\n",
    "        \n",
    "        # Compute positional embeddings from the Laplacian.\n",
    "        pos_emb = self._get_positional_embeddings(adj, self.pos_emb_dim)  # Shape: (N, pos_emb_dim)\n",
    "\n",
    "        # Compute strucrtural embeddings (random walk statistics).\n",
    "        rw_stats = self._get_random_walk_stats(adj)  # Shape: (N, 2)\n",
    "\n",
    "        # Concatenate positional embeddings and structural embeddings to raw node features.\n",
    "        x = torch.cat([x_raw, pos_emb, rw_stats], dim=1)  # Shape: (N, base_node_feature_dim + pos_emb_dim + 2)\n",
    "        \n",
    "        # Optionally, apply normalization (here we pass features through).\n",
    "        x_norm = self._normalize_node_features(x)\n",
    "        edge_attr_norm = self._normalize_edge_features(edge_attr)\n",
    "        \n",
    "        # For a single graph, assign all nodes to batch 0.\n",
    "        batch = torch.zeros(N, dtype=torch.long)\n",
    "        \n",
    "        data = {\n",
    "            'x': x,\n",
    "            'adj': adj,\n",
    "            'edge_attr': edge_attr,\n",
    "            'x_norm': x_norm,\n",
    "            'edge_attr_norm': edge_attr_norm,\n",
    "            'batch': batch\n",
    "        }\n",
    "        return data \n",
    "    \n",
    "    def _normalize_node_features(self, x):\n",
    "        \"\"\"Placeholder for node feature normalization.\"\"\"\n",
    "        return x\n",
    "\n",
    "    def _normalize_edge_features(self, edge_attr):\n",
    "        \"\"\"Placeholder for edge feature normalization.\"\"\"\n",
    "        return edge_attr\n",
    "    \n",
    "    def encode_smiles(self, smiles: str, device: torch.device) -> torch.Tensor:\n",
    "        \"\"\"Convert a SMILES string to a graph embedding\"\"\"\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            raise ValueError(f\"Could not parse SMILES: {smiles}\")\n",
    "        \n",
    "        # Optionally add hydrogen atoms\n",
    "        mol = Chem.AddHs(mol)\n",
    "        \n",
    "        # Convert to a graph data object\n",
    "        data = self._mol_to_graph_data(mol)\n",
    "        \n",
    "        # Create a batch with just this single molecule\n",
    "        data['batch'] = torch.zeros(data['x'].size(0), dtype=torch.long)\n",
    "\n",
    "        # Move all tensor entries to device.\n",
    "        for key in data:\n",
    "            if isinstance(data[key], torch.Tensor):\n",
    "                data[key] = data[key].to(device)\n",
    "        with torch.no_grad():\n",
    "            embedding = self.forward(data)\n",
    "        return embedding\n",
    "    \n",
    "    def encode_iupac(self, iupacs: str, device: torch.device) -> torch.Tensor:\n",
    "        pass\n",
    "    \n",
    "    def encode_batch(self, batch_data: List[str], device: torch.device) -> torch.Tensor:\n",
    "        \"\"\"Convert a batch of SMILES strings to graph embeddings\"\"\"\n",
    "        # Process each molecule individually\n",
    "        batch_embeddings = []\n",
    "        for smiles in batch_data:\n",
    "            embedding = self.encode_smiles(smiles, device)\n",
    "            batch_embeddings.append(embedding)\n",
    "        \n",
    "        # Stack all embeddings\n",
    "        batch = torch.cat(batch_embeddings, dim=0)\n",
    "        \n",
    "        return batch\n",
    "\n",
    "    def preprocess_dataset(self, smiles_list: List[str]):\n",
    "        \"\"\"Precompute normalization parameters for the dataset\"\"\"\n",
    "        # Convert all molecules to graphs and collect statistics\n",
    "        all_node_features = []\n",
    "        all_edge_features = []\n",
    "        \n",
    "        for smiles in smiles_list:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is None:\n",
    "                continue\n",
    "                \n",
    "            # Add hydrogens\n",
    "            #mol = Chem.AddHs(mol)\n",
    "            \n",
    "            # Collect node features\n",
    "            for atom in mol.GetAtoms():\n",
    "                features = self._get_atom_features(atom)\n",
    "                all_node_features.append(features)\n",
    "            \n",
    "            # Collect edge features\n",
    "            for bond in mol.GetBonds():\n",
    "                features = self._get_bond_features(bond)\n",
    "                all_edge_features.append(features)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        all_node_features = torch.tensor(all_node_features, dtype=torch.float)\n",
    "        all_edge_features = torch.tensor(all_edge_features, dtype=torch.float)\n",
    "        \n",
    "        # Compute normalization parameters\n",
    "        for i, feature_name in enumerate(self.node_features):\n",
    "            feature_values = all_node_features[:, i]\n",
    "            self.scalers[feature_name] = {\n",
    "                'min': float(feature_values.min()),\n",
    "                'max': float(feature_values.max()),\n",
    "                'mean': float(feature_values.mean()),\n",
    "                'std': float(feature_values.std())\n",
    "            }\n",
    "        \n",
    "        for i, feature_name in enumerate(self.edge_features):\n",
    "            feature_values = all_edge_features[:, i]\n",
    "            self.scalers[feature_name] = {\n",
    "                'min': float(feature_values.min()),\n",
    "                'max': float(feature_values.max()),\n",
    "                'mean': float(feature_values.mean()),\n",
    "                'std': float(feature_values.std())\n",
    "            }\n",
    "        \n",
    "        return self.scalers\n",
    "    \n",
    "    @property\n",
    "    def embedding_dim(self) -> int:\n",
    "        return self._embedding_dim\n",
    "    \n",
    "    def forward(self, data: dict) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Perform message passing to produce a graph-level embedding.\n",
    "        data: Dictionary containing keys 'x_norm', 'adj', 'edge_attr_norm', 'batch'.\n",
    "        \"\"\"\n",
    "        # Extract inputs.\n",
    "        x = data['x_norm']        # (N, node_feature_dim) where node_feature_dim = base (125) + pos_emb_dim\n",
    "        adj = data['adj']         # (N, N)\n",
    "        edge_attr = data['edge_attr_norm']  # (N, N, edge_feature_dim)\n",
    "        N = x.size(0)\n",
    "\n",
    "        # Initial projection to hidden state.\n",
    "        h = F.relu(self.initial_linear(x))  # (N, hidden_state_size)\n",
    "\n",
    "        # Message passing iterations.\n",
    "        for t in range(self.n_layers):\n",
    "            h_neighbors = h.unsqueeze(0).expand(N, N, self.hidden_state_size)  # (N, N, hidden_state_size)\n",
    "            msg_input = torch.cat([h_neighbors, edge_attr], dim=2)  # (N, N, hidden_state_size + edge_feature_dim)\n",
    "            msg_input_flat = msg_input.view(-1, self.hidden_state_size + self.edge_feature_dim)\n",
    "            messages_flat = self.f_message(msg_input_flat)  # (N*N, hidden_state_size)\n",
    "            messages = messages_flat.view(N, N, self.hidden_state_size)  # (N, N, hidden_state_size)\n",
    "            messages = messages * adj.unsqueeze(2)  # mask non-existent edges\n",
    "            m = messages.sum(dim=1)  # aggregate messages by sum: (N, hidden_state_size)\n",
    "            h = F.relu(self.f_update(torch.cat([h, m], dim=1)))  # update node states: (N, hidden_state_size)\n",
    "\n",
    "        # Global mean pooling.\n",
    "        graph_repr = h.sum(dim=0, keepdim=True)  # (1, hidden_state_size)\n",
    "        out = self.f_readout(graph_repr)  # (1, embedding_dim)\n",
    "        return out\n",
    "    \n",
    "# Hashmap for periodic table row (period) (used RdKit pt.GetRow())\n",
    "element_row = {\n",
    "    'H': 1,\n",
    "    'He': 1,\n",
    "    'Li': 2,\n",
    "    'Be': 2,\n",
    "    'B': 2,\n",
    "    'C': 2,\n",
    "    'N': 2,\n",
    "    'O': 2,\n",
    "    'F': 2,\n",
    "    'Ne': 2,\n",
    "    'Na': 3,\n",
    "    'Mg': 3,\n",
    "    'Al': 3,\n",
    "    'Si': 3,\n",
    "    'P': 3,\n",
    "    'S': 3,\n",
    "    'Cl': 3,\n",
    "    'Ar': 3,\n",
    "    'K': 4,\n",
    "    'Ca': 4,\n",
    "    'Sc': 4,\n",
    "    'Ti': 4,\n",
    "    'V': 4,\n",
    "    'Cr': 4,\n",
    "    'Mn': 4,\n",
    "    'Fe': 4,\n",
    "    'Co': 4,\n",
    "    'Ni': 4,\n",
    "    'Cu': 4,\n",
    "    'Zn': 4,\n",
    "    'Ga': 4,\n",
    "    'Ge': 4,\n",
    "    'As': 4,\n",
    "    'Se': 4,\n",
    "    'Br': 4,\n",
    "    'Kr': 4,\n",
    "    'Rb': 5,\n",
    "    'Sr': 5,\n",
    "    'Y': 5,\n",
    "    'Zr': 5,\n",
    "    'Nb': 5,\n",
    "    'Mo': 5,\n",
    "    'Tc': 5,\n",
    "    'Ru': 5,\n",
    "    'Rh': 5,\n",
    "    'Pd': 5,\n",
    "    'Ag': 5,\n",
    "    'Cd': 5,\n",
    "    'In': 5,\n",
    "    'Sn': 5,\n",
    "    'Sb': 5,\n",
    "    'Te': 5,\n",
    "    'I': 5,\n",
    "    'Xe': 5,\n",
    "    'Cs': 6,\n",
    "    'Ba': 6,\n",
    "    'La': 6,\n",
    "    'Ce': 6,\n",
    "    'Pr': 6,\n",
    "    'Nd': 6,\n",
    "    'Pm': 6,\n",
    "    'Sm': 6,\n",
    "    'Eu': 6,\n",
    "    'Gd': 6,\n",
    "    'Tb': 6,\n",
    "    'Dy': 6,\n",
    "    'Ho': 6,\n",
    "    'Er': 6,\n",
    "    'Tm': 6,\n",
    "    'Yb': 6,\n",
    "    'Lu': 6,\n",
    "    'Hf': 6,\n",
    "    'Ta': 6,\n",
    "    'W': 6,\n",
    "    'Re': 6,\n",
    "    'Os': 6,\n",
    "    'Ir': 6,\n",
    "    'Pt': 6,\n",
    "    'Au': 6,\n",
    "    'Hg': 6,\n",
    "    'Tl': 6,\n",
    "    'Pb': 6,\n",
    "    'Bi': 6,\n",
    "    'Po': 6,\n",
    "    'At': 6,\n",
    "    'Rn': 6,\n",
    "    'Fr': 7,\n",
    "    'Ra': 7,\n",
    "    'Ac': 7,\n",
    "    'Th': 7,\n",
    "    'Pa': 7,\n",
    "    'U': 7,\n",
    "    'Np': 7,\n",
    "    'Pu': 7,\n",
    "    'Am': 7,\n",
    "    'Cm': 7,\n",
    "    'Bk': 7,\n",
    "    'Cf': 7,\n",
    "    'Es': 7,\n",
    "    'Fm': 7,\n",
    "    'Md': 7,\n",
    "    'No': 7,\n",
    "    'Lr': 7,\n",
    "    'Rf': 7,\n",
    "    'Db': 7,\n",
    "    'Sg': 7,\n",
    "    'Bh': 7,\n",
    "    'Hs': 7,\n",
    "    'Mt': 7,\n",
    "    'Ds': 7,\n",
    "    'Rg': 7,\n",
    "    'Cn': 7,\n",
    "    'Nh': 7,\n",
    "    'Fl': 7,\n",
    "    'Mc': 7,\n",
    "    'Lv': 7,\n",
    "    'Ts': 7,\n",
    "    'Og': 7,\n",
    "}\n",
    "\n",
    "# Hashmap for periodic table column (group) (manually entered)\n",
    "element_col = {\n",
    "    'H': 1,\n",
    "    'He': 18,\n",
    "    'Li': 1,\n",
    "    'Be': 2,\n",
    "    'B': 13,\n",
    "    'C': 14,\n",
    "    'N': 15,\n",
    "    'O': 16,\n",
    "    'F': 17,\n",
    "    'Ne': 18,\n",
    "    'Na': 1,\n",
    "    'Mg': 2,\n",
    "    'Al': 13,\n",
    "    'Si': 14,\n",
    "    'P': 15,\n",
    "    'S': 16,\n",
    "    'Cl': 17,\n",
    "    'Ar': 18,\n",
    "    'K': 1,\n",
    "    'Ca': 2,\n",
    "    'Sc': 3,\n",
    "    'Ti': 4,\n",
    "    'V': 5,\n",
    "    'Cr': 6,\n",
    "    'Mn': 7,\n",
    "    'Fe': 8,\n",
    "    'Co': 9,\n",
    "    'Ni': 10,\n",
    "    'Cu': 11,\n",
    "    'Zn': 12,\n",
    "    'Ga': 13,\n",
    "    'Ge': 14,\n",
    "    'As': 15,\n",
    "    'Se': 16,\n",
    "    'Br': 17,\n",
    "    'Kr': 18,\n",
    "    'Rb': 1,\n",
    "    'Sr': 2,\n",
    "    'Y': 3,\n",
    "    'Zr': 4,\n",
    "    'Nb': 5,\n",
    "    'Mo': 6,\n",
    "    'Tc': 7,\n",
    "    'Ru': 8,\n",
    "    'Rh': 9,\n",
    "    'Pd': 10,\n",
    "    'Ag': 11,\n",
    "    'Cd': 12,\n",
    "    'In': 13,\n",
    "    'Sn': 14,\n",
    "    'Sb': 15,\n",
    "    'Te': 16,\n",
    "    'I': 17,\n",
    "    'Xe': 18,\n",
    "    'Cs': 1,\n",
    "    'Ba': 2,\n",
    "    'La': 0,\n",
    "    'Ce': 0,\n",
    "    'Pr': 0,\n",
    "    'Nd': 0,\n",
    "    'Pm': 0,\n",
    "    'Sm': 0,\n",
    "    'Eu': 0,\n",
    "    'Gd': 0,\n",
    "    'Tb': 0,\n",
    "    'Dy': 0,\n",
    "    'Ho': 0,\n",
    "    'Er': 0,\n",
    "    'Tm': 0,\n",
    "    'Yb': 0,\n",
    "    'Lu': 3,\n",
    "    'Hf': 4,\n",
    "    'Ta': 5,\n",
    "    'W': 6,\n",
    "    'Re': 7,\n",
    "    'Os': 8,\n",
    "    'Ir': 9,\n",
    "    'Pt': 10,\n",
    "    'Au': 11,\n",
    "    'Hg': 12,\n",
    "    'Tl': 13,\n",
    "    'Pb': 14,\n",
    "    'Bi': 15,\n",
    "    'Po': 16,\n",
    "    'At': 17,\n",
    "    'Rn': 18,\n",
    "    'Fr': 1,\n",
    "    'Ra': 2,\n",
    "    'Ac': 0,\n",
    "    'Th': 0,\n",
    "    'Pa': 0,\n",
    "    'U': 0,\n",
    "    'Np': 0,\n",
    "    'Pu': 0,\n",
    "    'Am': 0,\n",
    "    'Cm': 0,\n",
    "    'Bk': 0,\n",
    "    'Cf': 0,\n",
    "    'Es': 0,\n",
    "    'Fm': 0,\n",
    "    'Md': 0,\n",
    "    'No': 0,\n",
    "    'Lr': 3,\n",
    "    'Rf': 4,\n",
    "    'Db': 5,\n",
    "    'Sg': 6,\n",
    "    'Bh': 7,\n",
    "    'Hs': 8,\n",
    "    'Mt': 9,\n",
    "    'Ds': 10,\n",
    "    'Rg': 11,\n",
    "    'Cn': 12,\n",
    "    'Nh': 13,\n",
    "    'Fl': 14,\n",
    "    'Mc': 15,\n",
    "    'Lv': 16,\n",
    "    'Ts': 17,\n",
    "    'Og': 18,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbe78cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedGNNProteinEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Advanced Graph Neural Network-based Protein Encoder that incorporates:\n",
    "    - Rich amino acid feature representation\n",
    "    - Flexible graph structures (sequential, predicted contacts)\n",
    "    - Attention-based message passing\n",
    "    - Multiple readout functions\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 embedding_dim: int = 256, \n",
    "                 hidden_channels: int = 128,\n",
    "                 num_layers: int = 3,\n",
    "                 dropout: float = 0.2,\n",
    "                 use_attention: bool = True,\n",
    "                 readout_mode: str = 'mean'):\n",
    "        \"\"\"\n",
    "        Initialize the advanced GNN protein encoder.\n",
    "        \n",
    "        Args:\n",
    "            embedding_dim: Final embedding dimension\n",
    "            hidden_channels: Size of hidden layers in GNN\n",
    "            num_layers: Number of GNN layers\n",
    "            dropout: Dropout probability\n",
    "            use_attention: Whether to use attention-based message passing\n",
    "            readout_mode: Method for graph-level pooling ('mean', 'sum', 'max', 'mean+max')\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self._embedding_dim = embedding_dim\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.use_attention = use_attention\n",
    "        self.readout_mode = readout_mode\n",
    "        \n",
    "        # Feature dimensions\n",
    "        self.aa_embedding_dim = 20  # One-hot encoding of amino acids\n",
    "        self.physicochemical_dim = 12  # Various amino acid properties\n",
    "        self.position_embedding_dim = 16  # Positional encoding\n",
    "        \n",
    "        # Total node feature dimension\n",
    "        node_feature_dim = self.aa_embedding_dim + self.physicochemical_dim + self.position_embedding_dim\n",
    "        \n",
    "        # Amino acid mappings\n",
    "        self.aa_to_idx = {aa: i for i, aa in enumerate(\"ACDEFGHIKLMNPQRSTVWY\")}\n",
    "        self.default_idx = len(self.aa_to_idx)  # For unknown amino acids\n",
    "        \n",
    "        # Feature initialization layers\n",
    "        self.position_embedding = nn.Embedding(1000, self.position_embedding_dim)  # Max sequence length of 1000\n",
    "        \n",
    "        # Physicochemical property mappings (pre-computed)\n",
    "        self.aa_properties = self._initialize_aa_properties()\n",
    "        \n",
    "        # GNN layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        \n",
    "        # First layer takes the combined node features\n",
    "        if use_attention:\n",
    "            self.convs.append(GATConv(node_feature_dim, hidden_channels, heads=4, concat=False))\n",
    "        else:\n",
    "            self.convs.append(GCNConv(node_feature_dim, hidden_channels))\n",
    "        self.batch_norms.append(nn.BatchNorm1d(hidden_channels))\n",
    "        \n",
    "        # Additional layers\n",
    "        for _ in range(num_layers - 1):\n",
    "            if use_attention:\n",
    "                self.convs.append(GATConv(hidden_channels, hidden_channels, heads=4, concat=False))\n",
    "            else:\n",
    "                self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
    "            self.batch_norms.append(nn.BatchNorm1d(hidden_channels))\n",
    "        \n",
    "        # Output projections depend on readout mode\n",
    "        output_dim = hidden_channels if 'mean+max' not in readout_mode else hidden_channels * 2\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(output_dim, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_channels, embedding_dim)\n",
    "        )\n",
    "        \n",
    "    def _initialize_aa_properties(self) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Initialize physicochemical properties for each amino acid\"\"\"\n",
    "        properties = {}\n",
    "        \n",
    "        # These values are based on common AA properties: \n",
    "        # hydrophobicity, charge, size, polarity, etc.\n",
    "        \n",
    "        # Define key properties for each amino acid (normalized)\n",
    "        # Format: [hydrophobicity, charge, size, polarity, aromaticity, \n",
    "        #          h-bond donor, h-bond acceptor, pKa, pI, flexibility,\n",
    "        #          reactivity, glycosylation_site]\n",
    "        \n",
    "        properties['A'] = torch.tensor([0.7, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.1, 0.0])\n",
    "        properties['C'] = torch.tensor([0.8, 0.0, 0.2, 0.1, 0.0, 0.5, 0.0, 0.9, 0.4, 0.2, 0.9, 0.0])\n",
    "        properties['D'] = torch.tensor([0.3, -1.0, 0.3, 0.9, 0.0, 0.0, 1.0, 0.1, 0.3, 0.5, 0.4, 0.0])\n",
    "        properties['E'] = torch.tensor([0.4, -1.0, 0.4, 0.8, 0.0, 0.0, 1.0, 0.2, 0.3, 0.5, 0.3, 0.0])\n",
    "        properties['F'] = torch.tensor([0.9, 0.0, 0.6, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.2, 0.2, 0.0])\n",
    "        properties['G'] = torch.tensor([0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.2, 0.0])\n",
    "        properties['H'] = torch.tensor([0.5, 0.5, 0.5, 0.7, 0.5, 0.5, 0.5, 0.6, 0.7, 0.3, 0.6, 0.0])\n",
    "        properties['I'] = torch.tensor([1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.1, 0.1, 0.0])\n",
    "        properties['K'] = torch.tensor([0.3, 1.0, 0.6, 0.8, 0.0, 0.5, 0.0, 1.0, 0.9, 0.5, 0.3, 0.0])\n",
    "        properties['L'] = torch.tensor([0.9, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.2, 0.1, 0.0])\n",
    "        properties['M'] = torch.tensor([0.7, 0.0, 0.5, 0.1, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0])\n",
    "        properties['N'] = torch.tensor([0.3, 0.0, 0.3, 0.8, 0.0, 0.5, 0.5, 0.0, 0.5, 0.5, 0.3, 1.0])\n",
    "        properties['P'] = torch.tensor([0.5, 0.0, 0.3, 0.3, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.2, 0.0])\n",
    "        properties['Q'] = torch.tensor([0.4, 0.0, 0.4, 0.7, 0.0, 0.5, 0.5, 0.0, 0.5, 0.4, 0.2, 0.0])\n",
    "        properties['R'] = torch.tensor([0.2, 1.0, 0.7, 0.9, 0.0, 0.5, 0.0, 0.5, 1.0, 0.4, 0.3, 0.0])\n",
    "        properties['S'] = torch.tensor([0.4, 0.0, 0.2, 0.6, 0.0, 0.5, 0.5, 0.0, 0.5, 0.6, 0.2, 0.5])\n",
    "        properties['T'] = torch.tensor([0.5, 0.0, 0.3, 0.5, 0.0, 0.5, 0.5, 0.0, 0.5, 0.4, 0.2, 0.5])\n",
    "        properties['V'] = torch.tensor([0.8, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.2, 0.1, 0.0])\n",
    "        properties['W'] = torch.tensor([0.6, 0.0, 0.8, 0.1, 1.0, 0.5, 0.0, 0.0, 0.5, 0.1, 0.2, 0.0])\n",
    "        properties['Y'] = torch.tensor([0.7, 0.0, 0.7, 0.4, 0.8, 0.5, 0.5, 0.3, 0.5, 0.2, 0.3, 0.0])\n",
    "        \n",
    "        # Default for unknown amino acids (average values)\n",
    "        properties['X'] = torch.mean(torch.stack([prop for prop in properties.values()]), dim=0)\n",
    "        \n",
    "        return properties\n",
    "        \n",
    "    def _one_hot_encode_aa(self, aa: str) -> torch.Tensor:\n",
    "        \"\"\"One-hot encode an amino acid\"\"\"\n",
    "        idx = self.aa_to_idx.get(aa, self.default_idx)\n",
    "        one_hot = torch.zeros(self.aa_embedding_dim)\n",
    "        if idx < self.aa_embedding_dim:\n",
    "            one_hot[idx] = 1.0\n",
    "        return one_hot\n",
    "    \n",
    "    def _get_aa_properties(self, aa: str) -> torch.Tensor:\n",
    "        \"\"\"Get physicochemical properties for an amino acid\"\"\"\n",
    "        return self.aa_properties.get(aa, self.aa_properties['X'])\n",
    "    \n",
    "    def _sequence_to_graph(self, \n",
    "                          sequence: str, \n",
    "                          contact_map: Optional[Union[torch.Tensor, List, np.ndarray, None]] = None,\n",
    "                          distance_threshold: float = 8.0) -> Data:\n",
    "        \"\"\"\n",
    "        Convert a protein sequence to a graph representation.\n",
    "        \n",
    "        Args:\n",
    "            sequence: Amino acid sequence\n",
    "            contact_map: Optional tensor of pairwise distances/contacts\n",
    "            distance_threshold: Threshold for considering residues in contact\n",
    "            \n",
    "        Returns:\n",
    "            PyTorch Geometric Data object\n",
    "        \"\"\"\n",
    "        # Node features: combine one-hot encoding, properties, and position\n",
    "        x = []\n",
    "        for i, aa in enumerate(sequence):\n",
    "            if aa not in self.aa_to_idx and aa != 'X':\n",
    "                aa = 'X'  # Use default for unknown amino acids\n",
    "                \n",
    "            # Combine features\n",
    "            one_hot = self._one_hot_encode_aa(aa)\n",
    "            properties = self._get_aa_properties(aa)\n",
    "            position = self.position_embedding(torch.tensor([min(i, 999)]))\n",
    "            \n",
    "            # Concatenate all features\n",
    "            features = torch.cat([one_hot, properties, position.squeeze(0)])\n",
    "            x.append(features)\n",
    "            \n",
    "        # Create node features tensor\n",
    "        x = torch.stack(x)\n",
    "        \n",
    "        # Create edge index\n",
    "        edge_index = []\n",
    "        \n",
    "        # Add sequential connections (each AA connected to neighbors within window)\n",
    "        window_size = 3  # Connect each AA to this many neighbors in each direction\n",
    "        for i in range(len(sequence)):\n",
    "            # Connect to previous AAs within window\n",
    "            for w in range(1, window_size + 1):\n",
    "                if i - w >= 0:\n",
    "                    edge_index.append([i-w, i])\n",
    "                    edge_index.append([i, i-w])  # Bidirectional\n",
    "            \n",
    "            # Connect to next AAs within window\n",
    "            for w in range(1, window_size + 1):\n",
    "                if i + w < len(sequence):\n",
    "                    edge_index.append([i, i+w])\n",
    "                    edge_index.append([i+w, i])  # Bidirectional\n",
    "        \n",
    "        # Add contacts from contact map if provided\n",
    "        if contact_map is not None:\n",
    "            try:\n",
    "                # Convert to tensor if not already\n",
    "                if not isinstance(contact_map, torch.Tensor):\n",
    "                    if isinstance(contact_map, np.ndarray):\n",
    "                        contact_map = torch.tensor(contact_map)\n",
    "                    elif isinstance(contact_map, list):\n",
    "                        contact_map = torch.tensor(contact_map)\n",
    "                \n",
    "                # Only use contact map if it's now a tensor with the right shape\n",
    "                if isinstance(contact_map, torch.Tensor) and contact_map.dim() == 2:\n",
    "                    for i in range(len(sequence)):\n",
    "                        for j in range(i + window_size + 1, min(len(sequence), contact_map.shape[0])):\n",
    "                            # Check dimensions to avoid index errors\n",
    "                            if i < contact_map.shape[0] and j < contact_map.shape[1]:\n",
    "                                if contact_map[i, j] <= distance_threshold:\n",
    "                                    edge_index.append([i, j])\n",
    "                                    edge_index.append([j, i])  # Bidirectional\n",
    "            except Exception as e:\n",
    "                # If we encounter any error with the contact map, just ignore it\n",
    "                print(f\"Warning: Could not use contact map: {e}\")\n",
    "        \n",
    "        # Create edge index tensor\n",
    "        if edge_index:\n",
    "            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        else:\n",
    "            # Handle case with no edges (very short sequence)\n",
    "            edge_index = torch.zeros((2, 0), dtype=torch.long)\n",
    "        \n",
    "        # Create PyG Data object\n",
    "        data = Data(x=x, edge_index=edge_index)\n",
    "        return data\n",
    "    \n",
    "    def forward(self, data: Data) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Process protein graph through the GNN.\n",
    "        \n",
    "        Args:\n",
    "            data: PyTorch Geometric Data object\n",
    "            \n",
    "        Returns:\n",
    "            Protein embedding tensor\n",
    "        \"\"\"\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # Apply GNN layers with residual connections\n",
    "        for i in range(self.num_layers):\n",
    "            identity = x\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            x = self.batch_norms[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            \n",
    "            # Add residual connection if dimensions match\n",
    "            if i > 0 and x.size(-1) == identity.size(-1):\n",
    "                x = x + identity\n",
    "        \n",
    "        # Different pooling strategies\n",
    "        if self.readout_mode == 'mean':\n",
    "            x = global_mean_pool(x, batch)\n",
    "        elif self.readout_mode == 'sum':\n",
    "            x = global_add_pool(x, batch)\n",
    "        elif self.readout_mode == 'max':\n",
    "            # Manual implementation of max pooling\n",
    "            x_max, _ = global_max_pool(x, batch, dim=0)\n",
    "            x = x_max\n",
    "        elif self.readout_mode == 'mean+max':\n",
    "            x_mean = global_mean_pool(x, batch)\n",
    "            # Manual implementation of max pooling\n",
    "            x_max, _ = global_max_pool(x, batch, dim=0)\n",
    "            x = torch.cat([x_mean, x_max], dim=1)\n",
    "        \n",
    "        # Final projection\n",
    "        x = self.projection(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def encode_sequence(self, \n",
    "                         sequence: str, \n",
    "                         device: Optional[torch.device] = None,\n",
    "                         contact_map: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Encode a single protein sequence.\n",
    "        \n",
    "        Args:\n",
    "            sequence: Amino acid sequence\n",
    "            contact_map: Optional contact map for the protein\n",
    "            \n",
    "        Returns:\n",
    "            Embedding tensor\n",
    "        \"\"\"\n",
    "        # Convert sequence to graph\n",
    "        data = self._sequence_to_graph(sequence, contact_map)\n",
    "        \n",
    "        # Add batch dimension for single sequence\n",
    "        data.batch = torch.zeros(len(sequence), dtype=torch.long)\n",
    "        \n",
    "        # Move to device if specified\n",
    "        if device is not None:\n",
    "            data = data.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            embedding = self.forward(data)\n",
    "            \n",
    "        return embedding\n",
    "    \n",
    "    def encode_batch(self, \n",
    "                     batch_data: List[str],\n",
    "                     device: torch.device = None,\n",
    "                     contact_maps: Optional[List[torch.Tensor]] = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Encode a batch of protein sequences.\n",
    "        \n",
    "        Args:\n",
    "            batch_data: List of amino acid sequences\n",
    "            device: Device to place tensors on\n",
    "            contact_maps: Optional list of contact maps for each protein\n",
    "            \n",
    "        Returns:\n",
    "            Batch of embedding tensors\n",
    "        \"\"\"\n",
    "        # Create a list of Data objects\n",
    "        data_list = []\n",
    "        for sequence in batch_data:\n",
    "            # Don't use contact maps for now to avoid the error\n",
    "            data = self._sequence_to_graph(sequence, None)\n",
    "            data_list.append(data)\n",
    "            \n",
    "        # Create a batch from the list\n",
    "        batch = Batch.from_data_list(data_list)\n",
    "        \n",
    "        # Move to device if specified\n",
    "        if device is not None:\n",
    "            batch = batch.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            embeddings = self.forward(batch)\n",
    "            \n",
    "        return embeddings\n",
    "    \n",
    "    def predict_secondary_structure(self, sequence: str) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Predict secondary structure probabilities (helix, sheet, coil)\n",
    "        \n",
    "        Args:\n",
    "            sequence: Amino acid sequence\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of secondary structure probabilities\n",
    "        \"\"\"\n",
    "        # This would require a separate prediction head\n",
    "        # Here we use Biopython as a placeholder\n",
    "        try:\n",
    "            analysis = ProteinAnalysis(sequence)\n",
    "            helix, turn, sheet = analysis.secondary_structure_fraction()\n",
    "            \n",
    "            # Convert to tensor format that could come from a model\n",
    "            ss_pred = {\n",
    "                'helix': torch.tensor([helix] * len(sequence)),\n",
    "                'sheet': torch.tensor([sheet] * len(sequence)),\n",
    "                'coil': torch.tensor([turn] * len(sequence))\n",
    "            }\n",
    "            return ss_pred\n",
    "        except:\n",
    "            # Default values if analysis fails\n",
    "            return {\n",
    "                'helix': torch.zeros(len(sequence)),\n",
    "                'sheet': torch.zeros(len(sequence)),\n",
    "                'coil': torch.ones(len(sequence))\n",
    "            }\n",
    "    \n",
    "    def estimate_contact_map(self, sequence: str) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Estimate a contact map based on amino acid properties and sequential distance.\n",
    "        This is a placeholder - ideally a dedicated contact prediction model would be used.\n",
    "        \n",
    "        Args:\n",
    "            sequence: Amino acid sequence\n",
    "            \n",
    "        Returns:\n",
    "            Estimated contact map (distances between residues)\n",
    "        \"\"\"\n",
    "        seq_len = len(sequence)\n",
    "        contact_map = torch.ones(seq_len, seq_len) * 100  # Initialize with large distances\n",
    "        \n",
    "        # Set sequential distances\n",
    "        for i in range(seq_len):\n",
    "            for j in range(seq_len):\n",
    "                # Sequential distance penalty\n",
    "                contact_map[i, j] = min(contact_map[i, j], abs(i - j) * 3.8)\n",
    "                \n",
    "                # Reduce distance for hydrophobic interactions\n",
    "                aa_i = sequence[i] if sequence[i] in self.aa_to_idx else 'X'\n",
    "                aa_j = sequence[j] if sequence[j] in self.aa_to_idx else 'X'\n",
    "                hydrophobicity_i = self.aa_properties[aa_i][0]\n",
    "                hydrophobicity_j = self.aa_properties[aa_j][0]\n",
    "                \n",
    "                # Hydrophobic residues tend to cluster\n",
    "                if hydrophobicity_i > 0.7 and hydrophobicity_j > 0.7:\n",
    "                    contact_map[i, j] = min(contact_map[i, j], 8.0 + abs(i - j) * 0.5)\n",
    "                \n",
    "                # Ionic interactions between charged residues\n",
    "                charge_i = self.aa_properties[aa_i][1]\n",
    "                charge_j = self.aa_properties[aa_j][1]\n",
    "                if abs(i - j) > 4 and charge_i * charge_j < 0:  # Opposite charges attract\n",
    "                    contact_map[i, j] = min(contact_map[i, j], 10.0)\n",
    "                    \n",
    "        return contact_map\n",
    "    \n",
    "    @property\n",
    "    def embedding_dim(self) -> int:\n",
    "        return self._embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d10b1cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fractions_df = pd.read_csv('../pipeline/data/Train_Fractions.csv', sep='\\t')\n",
    "glycans_df = pd.read_csv('../pipeline/data/Glycan-Structures-CFG611.txt', sep='\\t')\n",
    "proteins_df = pd.read_csv('../pipeline/data/Protein-Sequence-Table.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2781f63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lg/qdb8l8gj3csbvxb_svgr1t0c0000gn/T/ipykernel_94757/1385069647.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  non_zero_df['f_bin'] = pd.cut(non_zero_df['f'], bins=bins, labels=labels, right=False)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = [0.0, 0.0001, 0.001, 0.005, 0.01, 0.015, 0.02, 0.03, 0.06, 0.1, 0.5, 1, 2, 5, 10]\n",
    "labels = ['<0.0001', '0.0001-0.001', '0.0010.005', '0.0050.01', '0.010.015', '0.0150.02',\n",
    "          '0.02-0.03', '0.03-0.06', '0.06-0.1', '0.1-0.5', '0.5-1', '1-2', '2-5', '5-10']\n",
    "\n",
    "# Add bin labels to the original data\n",
    "fractions_df['f_bin'] = pd.cut(fractions_df['f'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Count all values\n",
    "bin_counts_all = fractions_df['f_bin'].value_counts().sort_index()\n",
    "\n",
    "# Filter out zeros and count non-zero bins only\n",
    "non_zero_df = fractions_df[fractions_df['f'] > 0]\n",
    "non_zero_df['f_bin'] = pd.cut(non_zero_df['f'], bins=bins, labels=labels, right=False)\n",
    "bin_counts_nonzero = non_zero_df['f_bin'].value_counts().sort_index()\n",
    "\n",
    "# Plot side-by-side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "\n",
    "# All values plot\n",
    "bin_counts_all.plot(kind='bar', color='skyblue', edgecolor='black', ax=axes[0])\n",
    "axes[0].set_title('Binding Strength: All Values')\n",
    "axes[0].set_xlabel('Binding Value Bins')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].grid(axis='y')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "#axes[0].set_ylim(0, 50_000)\n",
    "\n",
    "# Non-zero values plot\n",
    "bin_counts_nonzero.plot(kind='bar', color='lightgreen', edgecolor='black', ax=axes[1])\n",
    "axes[1].set_title('Binding Strength: Non-Zero Only')\n",
    "axes[1].set_xlabel('Binding Value Bins')\n",
    "axes[1].grid(axis='y')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "#axes[1].set_ylim(0, 15_000)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "433e39b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Test size (% of glycans and proteins as combinations in test set): 50.0% -------------\n",
      "train size: 29582, test size: 8054, total: 68492\n",
      "train size: 43.19%, test size: 11.76%\n",
      "test size % in terms of test/(training+test) size: 21.4%\n",
      "Total % of dataset used: 54.95%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/test_env/lib/python3.12/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "device = torch.device(\"cpu\") # \"cuda\")\n",
    "glycan_encoder = MPNNGlycanEncoder().to(device) #GNNGlycanEncoder().to(device)\n",
    "protein_encoder = AdvancedGNNProteinEncoder().to(device) #AdvancedGNNProteinEncoder().to(device)\n",
    "\n",
    "glycan_type = 'SMILES'\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "split_mode = 'AND'\n",
    "use_kfolds = False\n",
    "k_folds = 0\n",
    "val_split = 0.5#0.35 # 0.35 if using OR, 0.5 if using AND\n",
    "#device = 'cpu'\n",
    "\n",
    "full_indicies, glycan_encodings, protein_encodings = prepare_train_val_datasets(fractions_df, glycans_df, proteins_df, glycan_encoder, protein_encoder, glycan_type, random_state, split_mode, use_kfolds, k_folds, val_split, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5b487ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change binds value of which values we want to consider as non binding\n",
    "non_binding_threshold = 0#0.0005\n",
    "\n",
    "train_idx, val_idx = full_indicies[0]\n",
    "fractions_df['binds'] = (fractions_df['f'] > non_binding_threshold).astype(int)\n",
    "train_data = fractions_df.loc[train_idx]\n",
    "val_data = fractions_df.loc[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b2e5277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29582, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "373bda5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15584"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[train_data['f'] > non_binding_threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c594cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8054, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "007f5bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3738"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data[val_data['f'] > non_binding_threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "828385dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ObjId</th>\n",
       "      <th>ProteinGroup</th>\n",
       "      <th>Concentration</th>\n",
       "      <th>GlycanID</th>\n",
       "      <th>f</th>\n",
       "      <th>f_bin</th>\n",
       "      <th>binds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6945</th>\n",
       "      <td>30551</td>\n",
       "      <td>1004624</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>CFG-008-Sp8</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.0001-0.001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6946</th>\n",
       "      <td>30552</td>\n",
       "      <td>1004624</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>CFG-009-Sp8</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.0001-0.001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6947</th>\n",
       "      <td>30553</td>\n",
       "      <td>1004624</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>CFG-010-Sp15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6952</th>\n",
       "      <td>30559</td>\n",
       "      <td>1004624</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>CFG-013-Sp8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6954</th>\n",
       "      <td>30562</td>\n",
       "      <td>1004624</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>CFG-016-Sp8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    ObjId  ProteinGroup  Concentration      GlycanID  \\\n",
       "6945       30551  1004624             9            0.1   CFG-008-Sp8   \n",
       "6946       30552  1004624             9            0.1   CFG-009-Sp8   \n",
       "6947       30553  1004624             9            0.1  CFG-010-Sp15   \n",
       "6952       30559  1004624             9            0.1   CFG-013-Sp8   \n",
       "6954       30562  1004624             9            0.1   CFG-016-Sp8   \n",
       "\n",
       "             f         f_bin  binds  \n",
       "6945  0.000255  0.0001-0.001      1  \n",
       "6946  0.000254  0.0001-0.001      1  \n",
       "6947  0.000000       <0.0001      0  \n",
       "6952  0.000000       <0.0001      0  \n",
       "6954  0.000000       <0.0001      0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "729f4fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create feature matrix by combining encodings\n",
    "def get_features(data_df, glycans_df, proteins_df, glycan_encodings, protein_encodings):\n",
    "    # Map glycan and protein indices\n",
    "    glycan_index_map = {name: i for i, name in enumerate(glycans_df['Name'])}\n",
    "    protein_index_map = {pg: i for i, pg in enumerate(proteins_df['ProteinGroup'])}\n",
    "\n",
    "    glycan_idx = data_df['GlycanID'].map(glycan_index_map).values\n",
    "    protein_idx = data_df['ProteinGroup'].map(protein_index_map).values\n",
    "\n",
    "    # Get encoded vectors from PyTorch tensors\n",
    "    glycan_feats = glycan_encodings[glycan_idx]\n",
    "    protein_feats = protein_encodings[protein_idx]\n",
    "\n",
    "    # Concatenate along feature dimension\n",
    "    full_feats = torch.cat([glycan_feats, protein_feats], dim=1)\n",
    "\n",
    "    return full_feats.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6247fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = get_features(train_data, glycans_df, proteins_df, glycan_encodings, protein_encodings)\n",
    "X_val = get_features(val_data, glycans_df, proteins_df, glycan_encodings, protein_encodings)\n",
    "\n",
    "y_train = train_data['binds'].values\n",
    "y_val = val_data['binds'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad392418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.5519\n",
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.51      0.55      4316\n",
      "           1       0.51      0.60      0.55      3738\n",
      "\n",
      "    accuracy                           0.55      8054\n",
      "   macro avg       0.56      0.56      0.55      8054\n",
      "weighted avg       0.56      0.55      0.55      8054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "log_clf = LogisticRegression(max_iter=1000)\n",
    "log_clf.fit(X_train, y_train)\n",
    "y_pred_log = log_clf.predict(X_val)\n",
    "\n",
    "log_acc = accuracy_score(y_val, y_pred_log)\n",
    "print(\"Logistic Regression Accuracy:\", round(log_acc, 4))\n",
    "print(\"Logistic Regression:\\n\", classification_report(y_val, y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66fff8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.5453\n",
      "Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.50      0.54      4316\n",
      "           1       0.51      0.60      0.55      3738\n",
      "\n",
      "    accuracy                           0.55      8054\n",
      "   macro avg       0.55      0.55      0.55      8054\n",
      "weighted avg       0.55      0.55      0.54      8054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_val)\n",
    "\n",
    "rf_acc = accuracy_score(y_val, y_pred_rf)\n",
    "print(\"Random Forest Accuracy:\", round(rf_acc, 4))\n",
    "print(\"Random Forest:\\n\", classification_report(y_val, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26840432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/test_env/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:09:20] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1744352353999/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.5248\n",
      "XGBoost:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.38      0.46      4316\n",
      "           1       0.49      0.70      0.58      3738\n",
      "\n",
      "    accuracy                           0.52      8054\n",
      "   macro avg       0.54      0.54      0.52      8054\n",
      "weighted avg       0.54      0.52      0.51      8054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_clf.predict(X_val)\n",
    "\n",
    "xgb_acc = accuracy_score(y_val, y_pred_xgb)\n",
    "print(\"XGBoost Accuracy:\", round(xgb_acc, 4))\n",
    "print(\"XGBoost:\\n\", classification_report(y_val, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbbcd78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlycoProteinDataset(Dataset):\n",
    "    def __init__(self, fractions_df, glycan_encodings, protein_encodings, glycan_mapping, protein_mapping):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            fractions_df: DataFrame with fraction data\n",
    "            glycan_encodings: Tensor of shape [n_glycans, embedding_dim]\n",
    "            protein_encodings: Tensor of shape [n_proteins, embedding_dim]\n",
    "            glycan_mapping: Dict mapping glycan IDs to indices in glycan_encodings\n",
    "            protein_mapping: Dict mapping protein IDs to indices in protein_encodings\n",
    "        \"\"\"\n",
    "        self.fractions_df = fractions_df\n",
    "        self.glycan_encodings = glycan_encodings\n",
    "        self.protein_encodings = protein_encodings\n",
    "        self.glycan_mapping = glycan_mapping\n",
    "        self.protein_mapping = protein_mapping\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.fractions_df)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.fractions_df.iloc[idx]\n",
    "        \n",
    "        # Get the corresponding encodings using the mappings\n",
    "        glycan_idx = self.glycan_mapping[row['GlycanID']]\n",
    "        protein_idx = self.protein_mapping[row['ProteinGroup']]\n",
    "        \n",
    "        return {\n",
    "            'glycan_encoding': self.glycan_encodings[glycan_idx],\n",
    "            'protein_encoding': self.protein_encodings[protein_idx],\n",
    "            'concentration': torch.tensor([row['Concentration']], dtype=torch.float32),\n",
    "            'binds': torch.tensor([row['binds']], dtype=torch.float32),\n",
    "            'target': torch.tensor([row['f']], dtype=torch.float32)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc80bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(predictions: torch.Tensor, targets: torch.Tensor) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate training/validation metrics\n",
    "    \n",
    "    Args:\n",
    "        predictions (torch.Tensor): Model predictions\n",
    "        targets (torch.Tensor): True values\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, float]: Dictionary of metric names and values\n",
    "    \"\"\"\n",
    "    # convert values to numpy arrays\n",
    "    preds_np = predictions.detach().cpu().numpy()\n",
    "    targets_np = targets.detach().cpu().numpy()\n",
    "    \n",
    "    mse = np.mean((preds_np - targets_np) ** 2)\n",
    "    pearson_corr, _ = pearsonr(preds_np.flatten(), targets_np.flatten())\n",
    "    \n",
    "    return {\n",
    "        'mse': float(mse),\n",
    "        'pearson': float(pearson_corr)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "809c6bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_Binary_BindingPredictor(nn.Module):\n",
    "    def __init__(self, glycan_dim: int, protein_dim: int, hidden_dims: List[int] = [385, 256, 128]):\n",
    "        \"\"\"\n",
    "        Simple DNN for binding prediction\n",
    "        \n",
    "        Args:\n",
    "            glycan_dim (int): Dimension of glycan embeddings\n",
    "            protein_dim (int): Dimension of protein embeddings\n",
    "            hidden_dims (List[int]): List of hidden layer dimensions\n",
    "        \"\"\"\n",
    "        super(DNN_Binary_BindingPredictor, self).__init__()\n",
    "        #super().__init__()#glycan_dim, protein_dim)\n",
    "                \n",
    "        input_dim = glycan_dim + protein_dim + 1 # total input feature size\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            *[nn.Sequential(\n",
    "                nn.Linear(input_dim if i==0 else hidden_dims[i-1], hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.Dropout(0.2)\n",
    "            ) for i, hidden_dim in enumerate(hidden_dims)],\n",
    "            nn.Linear(hidden_dims[-1], 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, \n",
    "                glycan_encoding: torch.Tensor,\n",
    "                protein_encoding: torch.Tensor,\n",
    "                concentration: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        \n",
    "        Args:\n",
    "            glycan_encoding (torch.Tensor): Encoded glycan representation\n",
    "            protein_encoding (torch.Tensor): Encoded protein representation\n",
    "            concentration (torch.Tensor): Concentration values\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Predicted fraction bound (values between 0 and 1)\n",
    "        \"\"\"\n",
    "        # combine input features\n",
    "        x = torch.cat([\n",
    "            glycan_encoding,\n",
    "            protein_encoding,\n",
    "            concentration\n",
    "        ], dim=-1)\n",
    "        \n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a520a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNBindingPredictor(nn.Module):\n",
    "    def __init__(self, glycan_dim: int, protein_dim: int, hidden_dims: List[int] = [512, 256, 128]):\n",
    "        \"\"\"\n",
    "        Simple DNN for binding prediction\n",
    "        \n",
    "        Args:\n",
    "            glycan_dim (int): Dimension of glycan embeddings\n",
    "            protein_dim (int): Dimension of protein embeddings\n",
    "            hidden_dims (List[int]): List of hidden layer dimensions\n",
    "        \"\"\"\n",
    "        super(DNNBindingPredictor, self).__init__()#glycan_dim, protein_dim)\n",
    "                \n",
    "        input_dim = glycan_dim + protein_dim + 1 # total input feature size\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            *[nn.Sequential(\n",
    "                nn.Linear(input_dim if i==0 else hidden_dims[i-1], hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.Dropout(0.2)\n",
    "            ) for i, hidden_dim in enumerate(hidden_dims)],\n",
    "            nn.Linear(hidden_dims[-1], 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, \n",
    "                glycan_encoding: torch.Tensor,\n",
    "                protein_encoding: torch.Tensor,\n",
    "                concentration: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        \n",
    "        Args:\n",
    "            glycan_encoding (torch.Tensor): Encoded glycan representation\n",
    "            protein_encoding (torch.Tensor): Encoded protein representation\n",
    "            concentration (torch.Tensor): Concentration values\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Predicted fraction bound (values between 0 and 1)\n",
    "        \"\"\"\n",
    "        # combine input features\n",
    "        x = torch.cat([\n",
    "            glycan_encoding,\n",
    "            protein_encoding,\n",
    "            concentration\n",
    "        ], dim=-1)\n",
    "        \n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57ae4c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re add here just for resets and testing other params\n",
    "glycan_encoder = MPNNGlycanEncoder().to(device) #GNNGlycanEncoder().to(device)\n",
    "protein_encoder = AdvancedGNNProteinEncoder().to(device) #AdvancedGNNProteinEncoder().to(device)\n",
    "\n",
    "glycan_mapping = {name: idx for idx, name in enumerate(glycans_df['Name'])}\n",
    "protein_mapping = {name: idx for idx, name in enumerate(proteins_df['ProteinGroup'])}\n",
    "\n",
    "train_idx, val_idx = full_indicies[0]\n",
    "\n",
    "train_data = fractions_df.loc[train_idx]\n",
    "val_data = fractions_df.loc[val_idx]\n",
    "\n",
    "train_pytorch_dataset = GlycoProteinDataset(\n",
    "    train_data, glycan_encodings, protein_encodings, glycan_mapping, protein_mapping\n",
    ")\n",
    "val_pytorch_dataset = GlycoProteinDataset(\n",
    "    val_data, glycan_encodings, protein_encodings, glycan_mapping, protein_mapping\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_pytorch_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_pytorch_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a96a6da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim: 385\n"
     ]
    }
   ],
   "source": [
    "input_dim = glycan_encoder.embedding_dim + protein_encoder.embedding_dim + 1  # Input dimension (glycan + protein + concentration)\n",
    "print('input dim:', input_dim)\n",
    "\n",
    "\n",
    "binding_predictor = DNN_Binary_BindingPredictor(glycan_dim=glycan_encoder.embedding_dim, protein_dim=protein_encoder.embedding_dim, hidden_dims=[256, 128, 64, 32]).to(device)\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    list(glycan_encoder.parameters()) +\n",
    "    list(protein_encoder.parameters()) +\n",
    "    list(binding_predictor.parameters()),\n",
    "    lr=learning_rate\n",
    ")\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss() #nn.MSELoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "431b1fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_epoch(train_type, zero_pred_threshold, train_loader, binding_predictor, glycan_encoder, protein_encoder, optimizer, criterion, device) -> Dict[str, float]:\n",
    "        glycan_encoder.train()\n",
    "        protein_encoder.train()\n",
    "        binding_predictor.train()\n",
    "        \n",
    "        total_loss = 0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc='Training')\n",
    "        for batch in pbar:\n",
    "            \n",
    "            #print(batch)\n",
    "            \n",
    "            glycan_encoding = batch['glycan_encoding'].to(device)\n",
    "            protein_encoding = batch['protein_encoding'].to(device)\n",
    "            concentration = batch['concentration'].to(device)\n",
    "            \n",
    "            if train_type == 'binary':\n",
    "                targets = batch['binds'].to(device)\n",
    "            else:\n",
    "                targets = batch['target'].to(device)\n",
    "            \n",
    "            predictions = binding_predictor(\n",
    "                glycan_encoding,\n",
    "                protein_encoding,\n",
    "                concentration\n",
    "            )\n",
    "\n",
    "            # Prevent double-log when using both log_predict=True and a log-based loss\n",
    "            #apply_log = self.config.log_predict and self.config.loss_type not in ['rmsle', 'log_mae', 'log_l1']\n",
    "            #if apply_log:\n",
    "            targets = torch.log(targets + 1)\n",
    "            predictions = torch.log(predictions + 1)\n",
    "            \n",
    "            \n",
    "            loss = criterion(predictions, targets)\n",
    "            \n",
    "            # reset gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            # perform backpropagation to calculate the gradients we need to improve model\n",
    "            loss.backward(retain_graph=True)\n",
    "            # update the weights with our loss gradients\n",
    "            optimizer.step()\n",
    "            \n",
    "            # revert predictions and targets to original values for original analysis if using log transform\n",
    "            #if apply_log:\n",
    "            predictions = torch.exp(predictions) - 1\n",
    "            targets = torch.exp(targets) - 1\n",
    "            \n",
    "            # track totals\n",
    "            total_loss += loss.item()\n",
    "            all_predictions.append(predictions.detach())\n",
    "            all_targets.append(targets.detach())\n",
    "            \n",
    "            # Update progress bar with current loss\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        # save metrics\n",
    "        epoch_predictions = torch.cat(all_predictions)\n",
    "        epoch_targets = torch.cat(all_targets)\n",
    "        \n",
    "        if train_type == 'binary':\n",
    "            epoch_predictions_binary = (epoch_predictions >= zero_pred_threshold).int()\n",
    "            epoch_targets_binary = epoch_targets.int()\n",
    "            \n",
    "            acc = (epoch_predictions_binary == epoch_targets_binary).float().mean()\n",
    "\n",
    "            print('metrics == accuracy')\n",
    "            metrics = float(acc)\n",
    "        else:\n",
    "            metrics = calculate_metrics(epoch_predictions, epoch_targets)\n",
    "        \n",
    "        print('Train')\n",
    "        print('total loss:', total_loss)\n",
    "        print('Metrics:', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96216aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _validate(train_type, zero_pred_threshold,\n",
    "              val_loader, binding_predictor, glycan_encoder, protein_encoder, criterion, device) -> Dict[str, float]:\n",
    "        glycan_encoder.eval()\n",
    "        protein_encoder.eval()\n",
    "        binding_predictor.eval()\n",
    "        \n",
    "        total_loss = 0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(val_loader, desc='Validating')\n",
    "            for batch in pbar:\n",
    "                \n",
    "                \n",
    "                glycan_encoding = batch['glycan_encoding'].to(device)\n",
    "                protein_encoding = batch['protein_encoding'].to(device)\n",
    "                concentration = batch['concentration'].to(device)\n",
    "                \n",
    "                if train_type == 'binary':\n",
    "                    targets = batch['binds'].to(device)\n",
    "                else:\n",
    "                    targets = batch['target'].to(device)\n",
    "                \n",
    "                \n",
    "                predictions = binding_predictor(\n",
    "                    glycan_encoding,\n",
    "                    protein_encoding,\n",
    "                    concentration\n",
    "                )\n",
    "\n",
    "                # Prevent double-log when using both log_predict=True and a log-based loss\n",
    "                #apply_log = self.config.log_predict and self.config.loss_type not in ['rmsle', 'log_mae', 'log_l1']\n",
    "                #if apply_log:\n",
    "                targets = torch.log(targets + 1)\n",
    "                predictions = torch.log(predictions + 1)\n",
    "                \n",
    "                loss = criterion(predictions, targets)\n",
    "                \n",
    "                # revert predictions and targets to original values for original analysis if using log transform\n",
    "                #$if apply_log:\n",
    "                predictions = torch.exp(predictions) - 1\n",
    "                targets = torch.exp(targets) - 1\n",
    "                \n",
    "                # track totals\n",
    "                total_loss += loss.item()\n",
    "                all_predictions.append(predictions)\n",
    "                all_targets.append(targets)\n",
    "                \n",
    "                # Update progress bar with current loss\n",
    "                pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        # save metrics\n",
    "        val_predictions = torch.cat(all_predictions)\n",
    "        val_targets = torch.cat(all_targets)\n",
    "        \n",
    "        if train_type == 'binary':\n",
    "            epoch_predictions_binary = (val_predictions >= zero_pred_threshold).int()\n",
    "            epoch_targets_binary = val_targets.int()\n",
    "            \n",
    "            acc = (epoch_predictions_binary == epoch_targets_binary).float().mean()\n",
    "\n",
    "            print('metrics == accuracy')\n",
    "            metrics = float(acc)\n",
    "        else:\n",
    "            metrics = calculate_metrics(val_predictions, val_targets)\n",
    "        \n",
    "        print('Validation')\n",
    "        print('total loss:', total_loss)\n",
    "        print('Metrics:', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67bda2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 925/925 [00:05<00:00, 163.26it/s, loss=0.7681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics == accuracy\n",
      "Train\n",
      "total loss: 600.3490109443665\n",
      "Metrics: 0.5631126761436462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 252/252 [00:00<00:00, 343.68it/s, loss=0.6771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics == accuracy\n",
      "Validation\n",
      "total loss: 156.0499805212021\n",
      "Metrics: 0.6001986861228943\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 925/925 [00:04<00:00, 186.39it/s, loss=0.6761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics == accuracy\n",
      "Train\n",
      "total loss: 595.1162474155426\n",
      "Metrics: 0.5737272500991821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 252/252 [00:00<00:00, 366.28it/s, loss=0.5712]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics == accuracy\n",
      "Validation\n",
      "total loss: 156.15266609191895\n",
      "Metrics: 0.6044201850891113\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 925/925 [00:05<00:00, 184.55it/s, loss=0.7272]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics == accuracy\n",
      "Train\n",
      "total loss: 593.6047070026398\n",
      "Metrics: 0.580048680305481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 252/252 [00:00<00:00, 369.72it/s, loss=0.5925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics == accuracy\n",
      "Validation\n",
      "total loss: 156.8146932721138\n",
      "Metrics: 0.5938664078712463\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 925/925 [00:05<00:00, 183.65it/s, loss=0.5781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics == accuracy\n",
      "Train\n",
      "total loss: 592.9198585152626\n",
      "Metrics: 0.5805557370185852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 252/252 [00:00<00:00, 359.50it/s, loss=0.6841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics == accuracy\n",
      "Validation\n",
      "total loss: 157.15638652443886\n",
      "Metrics: 0.5681648850440979\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 925/925 [00:05<00:00, 181.83it/s, loss=0.7389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics == accuracy\n",
      "Train\n",
      "total loss: 592.2744877934456\n",
      "Metrics: 0.5863363146781921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 252/252 [00:00<00:00, 361.12it/s, loss=0.6513]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics == accuracy\n",
      "Validation\n",
      "total loss: 157.04960376024246\n",
      "Metrics: 0.5537620782852173\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "zero_pred_threshold = 0.5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    train_metrics = _train_epoch('binary', zero_pred_threshold, train_loader, binding_predictor, glycan_encoder, protein_encoder, optimizer, criterion, device)\n",
    "    val_metrics = _validate('binary', zero_pred_threshold, val_loader, binding_predictor, glycan_encoder, protein_encoder, criterion, device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5087816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(glycan_encoder.state_dict(), \"./binary_binding_classif/glycan_encoder_weights.pth\")\n",
    "#torch.save(protein_encoder.state_dict(), \"./binary_binding_classif/protein_encoder_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd3ebb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#glycan_encoder.load_state_dict(torch.load(\"./binary_binding_classif/glycan_encoder_weights.pth\", map_location=device))\n",
    "#protein_encoder.load_state_dict(torch.load(\"./binary_binding_classif/protein_encoder_weights.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62cd9079",
   "metadata": {},
   "outputs": [],
   "source": [
    "glycan_encodings = glycan_encoder.encode_batch(glycans_df[glycan_type].tolist(), device)\n",
    "protein_encodings = protein_encoder.encode_batch(proteins_df['Amino Acid Sequence'].tolist(), device)\n",
    "X_train = get_features(train_data, glycans_df, proteins_df, glycan_encodings, protein_encodings)\n",
    "X_val = get_features(val_data, glycans_df, proteins_df, glycan_encodings, protein_encodings)\n",
    "\n",
    "y_train = train_data['binds'].values\n",
    "y_val = val_data['binds'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cd5b873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.5942\n",
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.64      4316\n",
      "           1       0.57      0.50      0.53      3738\n",
      "\n",
      "    accuracy                           0.59      8054\n",
      "   macro avg       0.59      0.59      0.59      8054\n",
      "weighted avg       0.59      0.59      0.59      8054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "log_clf = LogisticRegression(max_iter=1000)\n",
    "log_clf.fit(X_train, y_train)\n",
    "y_pred_log = log_clf.predict(X_val)\n",
    "\n",
    "log_acc = accuracy_score(y_val, y_pred_log)\n",
    "print(\"Logistic Regression Accuracy:\", round(log_acc, 4))\n",
    "print(\"Logistic Regression:\\n\", classification_report(y_val, y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a8fecc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ObjId</th>\n",
       "      <th>ProteinGroup</th>\n",
       "      <th>Concentration</th>\n",
       "      <th>GlycanID</th>\n",
       "      <th>f</th>\n",
       "      <th>f_bin</th>\n",
       "      <th>binds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6945</th>\n",
       "      <td>30551</td>\n",
       "      <td>1004624</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>CFG-008-Sp8</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.0001-0.001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6946</th>\n",
       "      <td>30552</td>\n",
       "      <td>1004624</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>CFG-009-Sp8</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.0001-0.001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6947</th>\n",
       "      <td>30553</td>\n",
       "      <td>1004624</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>CFG-010-Sp15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    ObjId  ProteinGroup  Concentration      GlycanID  \\\n",
       "6945       30551  1004624             9            0.1   CFG-008-Sp8   \n",
       "6946       30552  1004624             9            0.1   CFG-009-Sp8   \n",
       "6947       30553  1004624             9            0.1  CFG-010-Sp15   \n",
       "\n",
       "             f         f_bin  binds  \n",
       "6945  0.000255  0.0001-0.001      1  \n",
       "6946  0.000254  0.0001-0.001      1  \n",
       "6947  0.000000       <0.0001      0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a8b3172",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = get_features(val_data, glycans_df, proteins_df, glycan_encodings, protein_encodings)\n",
    "\n",
    "val_preds = log_clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf128368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for predicted-zero group: 0.002279\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Step 2: Get indices where model predicted \"no binding\" (0)\n",
    "zero_pred_mask = val_preds == 0\n",
    "\n",
    "# Step 3: Get true binding values (target 'f') for those rows\n",
    "true_f_values = val_data.loc[zero_pred_mask, 'f'].values\n",
    "\n",
    "# Step 4: Create predicted array of all zeros\n",
    "predicted_zeros = np.zeros_like(true_f_values)\n",
    "\n",
    "# Step 5: Calculate MSE\n",
    "mse_no_binding_preds = mean_squared_error(true_f_values, predicted_zeros)\n",
    "\n",
    "print(f\"MSE for predicted-zero group: {mse_no_binding_preds:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "508610c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_train = train_data[train_data['binds'] == 1]\n",
    "\n",
    "non_zero_val = val_data[val_preds == 1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37de0a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new data and encoders only for predicting non zero binds\n",
    "non_zero_train_pytorch_dataset = GlycoProteinDataset(\n",
    "    non_zero_train, glycan_encodings, protein_encodings, glycan_mapping, protein_mapping\n",
    ")\n",
    "non_zero_val_pytorch_dataset = GlycoProteinDataset(\n",
    "    non_zero_val, glycan_encodings, protein_encodings, glycan_mapping, protein_mapping\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "non_zero_train_loader = DataLoader(\n",
    "    non_zero_train_pytorch_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "non_zero_val_loader = DataLoader(\n",
    "    non_zero_val_pytorch_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "non_zero_glycan_encoder = MPNNGlycanEncoder().to(device) #GNNGlycanEncoder().to(device)\n",
    "non_zero_protein_encoder = AdvancedGNNProteinEncoder().to(device) #AdvancedGNNProteinEncoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "339359b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim: 385\n"
     ]
    }
   ],
   "source": [
    "input_dim = glycan_encoder.embedding_dim + protein_encoder.embedding_dim + 1  # Input dimension (glycan + protein + concentration)\n",
    "print('input dim:', input_dim)\n",
    "\n",
    "\n",
    "non_zero_binding_predictor = DNNBindingPredictor(glycan_dim=non_zero_glycan_encoder.embedding_dim, protein_dim=non_zero_protein_encoder.embedding_dim, hidden_dims=[256, 128, 64]).to(device)\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    list(non_zero_glycan_encoder.parameters()) +\n",
    "    list(non_zero_protein_encoder.parameters()) +\n",
    "    list(non_zero_binding_predictor.parameters()),\n",
    "    lr=learning_rate\n",
    ")\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "318e61d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 487/487 [00:02<00:00, 181.43it/s, loss=0.0044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "total loss: 23.80861213989556\n",
      "Metrics: {'mse': 0.08932340145111084, 'pearson': 0.09256148338317871}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 102/102 [00:00<00:00, 283.56it/s, loss=0.0272]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "total loss: 2.0270349169149995\n",
      "Metrics: {'mse': 0.03295329213142395, 'pearson': 0.07720168679952621}\n",
      "Epoch 2/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 487/487 [00:02<00:00, 194.36it/s, loss=0.0162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "total loss: 4.333120379538741\n",
      "Metrics: {'mse': 0.01341945119202137, 'pearson': 0.045443519949913025}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 102/102 [00:00<00:00, 243.41it/s, loss=0.0085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "total loss: 0.5604532556608319\n",
      "Metrics: {'mse': 0.008463953621685505, 'pearson': 0.1132236048579216}\n",
      "Epoch 3/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 487/487 [00:02<00:00, 197.88it/s, loss=0.0025]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "total loss: 3.8832379291998222\n",
      "Metrics: {'mse': 0.011983455158770084, 'pearson': 0.06450251489877701}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 102/102 [00:00<00:00, 242.90it/s, loss=0.0128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "total loss: 0.5626282336888835\n",
      "Metrics: {'mse': 0.008502057753503323, 'pearson': 0.08968639373779297}\n",
      "Epoch 4/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 487/487 [00:02<00:00, 194.22it/s, loss=0.0053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "total loss: 3.8006074322911445\n",
      "Metrics: {'mse': 0.011734717525541782, 'pearson': 0.10985208302736282}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 102/102 [00:00<00:00, 249.11it/s, loss=0.0072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "total loss: 0.562719415378524\n",
      "Metrics: {'mse': 0.008554317988455296, 'pearson': 0.057929374277591705}\n",
      "Epoch 5/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 487/487 [00:02<00:00, 198.69it/s, loss=0.0078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "total loss: 3.814421143004438\n",
      "Metrics: {'mse': 0.011782393790781498, 'pearson': 0.0909886583685875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 102/102 [00:00<00:00, 246.16it/s, loss=0.0024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "total loss: 0.5473391629639082\n",
      "Metrics: {'mse': 0.008354895748198032, 'pearson': 0.15550819039344788}\n",
      "Epoch 6/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 487/487 [00:02<00:00, 198.10it/s, loss=0.0042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "total loss: 3.787656568107195\n",
      "Metrics: {'mse': 0.011706119403243065, 'pearson': 0.10807929933071136}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 102/102 [00:00<00:00, 240.81it/s, loss=0.0096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "total loss: 0.5637488710635807\n",
      "Metrics: {'mse': 0.008497578091919422, 'pearson': 0.10856620967388153}\n",
      "Epoch 7/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 487/487 [00:02<00:00, 195.53it/s, loss=0.0009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "total loss: 3.7450768709823024\n",
      "Metrics: {'mse': 0.011569381691515446, 'pearson': 0.13433405756950378}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 102/102 [00:00<00:00, 242.79it/s, loss=0.0009]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "total loss: 0.5541557292162906\n",
      "Metrics: {'mse': 0.008404361084103584, 'pearson': 0.13521692156791687}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 7\n",
    "#doesnt matter here\n",
    "zero_pred_threshold = 0.5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    \n",
    "    # Training phase\n",
    "    train_metrics = _train_epoch('regression', zero_pred_threshold, non_zero_train_loader, non_zero_binding_predictor, non_zero_glycan_encoder, non_zero_protein_encoder, optimizer, criterion, device)\n",
    "    \n",
    "\n",
    "    val_metrics = _validate('regression', zero_pred_threshold, non_zero_val_loader, non_zero_binding_predictor, non_zero_glycan_encoder, non_zero_protein_encoder, criterion, device)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f32644f",
   "metadata": {},
   "source": [
    "## Combine all into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c0faa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = log_clf.predict(X_val)  # binary 0/1\n",
    "\n",
    "non_zero_binding_predictor.eval()\n",
    "non_zero_glycan_encoder.eval()\n",
    "non_zero_protein_encoder.eval()\n",
    "\n",
    "non_zero_predictions = []\n",
    "non_zero_indices = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(non_zero_val_loader):\n",
    "        glycan_encoding = batch['glycan_encoding'].to(device)\n",
    "        protein_encoding = batch['protein_encoding'].to(device)\n",
    "        concentration = batch['concentration'].to(device)\n",
    "\n",
    "        preds = non_zero_binding_predictor(\n",
    "            glycan_encoding,\n",
    "            protein_encoding,\n",
    "            concentration\n",
    "        )\n",
    "        non_zero_predictions.append(preds.cpu())\n",
    "        # Track index from val_data to place back into full prediction array\n",
    "        non_zero_indices.extend(batch['target'].cpu().numpy().tolist())  # Optionally keep row index\n",
    "\n",
    "\n",
    "non_zero_predictions = torch.cat(non_zero_predictions).squeeze().numpy()\n",
    "\n",
    "\n",
    "# Step 3a: Start with all zeros (logistic model predicts 0  predict 0.0)\n",
    "full_predictions = np.zeros(len(val_data))\n",
    "\n",
    "# Step 3b: Get indices where logistic model predicted 1 (non-zero)\n",
    "non_zero_indices_mask = val_preds == 1\n",
    "\n",
    "# Step 3c: Fill those predictions with actual predicted values\n",
    "full_predictions[non_zero_indices_mask] = non_zero_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed4e3b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-inflated hybrid model MSE: 0.004905\n"
     ]
    }
   ],
   "source": [
    "true_targets = val_data['f'].values\n",
    "hybrid_mse = mean_squared_error(true_targets, full_predictions)\n",
    "\n",
    "print(f\"Zero-inflated hybrid model MSE: {hybrid_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4cc77ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mse': 0.004904500173293548, 'pearson': 0.07773509634687722}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = calculate_metrics(torch.from_numpy(full_predictions), torch.from_numpy(true_targets))\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab50457",
   "metadata": {},
   "source": [
    "Use zero-inflated regression models like ZeroInflatedGamma, ZeroInflatedPoisson (mainly for count data, but some packages support continuous).\n",
    "\n",
    "could build a two-head model: one head predicts probability of binding, another predicts continuous strength (similar to multitask learning).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
